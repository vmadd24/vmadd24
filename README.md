# Hi, Iâ€™m Vishwanath Maddula ğŸ‘‹

**Software Engineer | Backend & Data Engineering**  
I build scalable backend systems and data platforms using **Java, Python, SQL, Airflow, Spark, and Cloud technologies (GCP/AWS)**. My work focuses on reliable ETL pipelines, cloud-native microservices, and analytics-ready data systems.

ğŸ“ United States  
ğŸ“§ vishwanathmaddula24@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/vishwanath-maddula-06b1871aa) | [GitHub](https://github.com/vmadd24) | [LeetCode](https://leetcode.com/u/vmadd01/)

---

## ğŸš€ What I Work On
- Backend development with **Java, Spring Boot, Python, Flask**
- Building **ETL / ELT pipelines** using Airflow, PySpark, and Cloud-native tools
- Streaming & event-driven systems (Kafka, Pub/Sub)
- Advanced **SQL analytics, query optimization, and data modeling**
- Designing production-grade, testable, and scalable systems

---

## ğŸ›  Tech Stack
**Languages:** Java, Python, SQL, JavaScript  
**Backend & APIs:** Spring Boot, Spring Cloud, Flask, RESTful APIs, Microservices  
**Data Engineering:** Airflow, PySpark, Apache Beam, Kafka, Pub/Sub, ETL/ELT, dbt, SODA  
**Databases:** PostgreSQL, MySQL, MongoDB, BigQuery, Elasticsearch  
**Cloud & DevOps:** GCP, AWS, Docker, Terraform, GitHub Actions, CI/CD  
**Analytics & Monitoring:** Pandas, NumPy, Statistics, Power BI, Looker  
**Testing & Tools:** JUnit, Pytest, Postman  
**Systems & Security:** Linux, Windows, TCP/IP, OSI Model, OWASP Best Practices

---

## ğŸ’¼ Experience

### Data Engineer / Software Engineer â€“ Data Analytics Platform  
**FoodSupply AI** | *Mar 2025 â€“ Present*
- Developed and maintained batch data pipelines using **Python, PySpark, and Airflow (Cloud Composer)**, processing **3GB+ daily marketing data** on GCP.
- Designed large-scale analytics pipelines using **Apache Beam on Cloud Dataflow**, delivering insights through BigQuery.
- Built **RESTful APIs (Flask, Spring Boot)** to serve processed data to internal dashboards and services.
- Optimized complex **BigQuery SQL** workloads, reducing execution time by **30â€“35%**.
- Contributed to **CI/CD automation** with GitHub Actions and Terraform; added monitoring and health checks for Airflow DAGs.

### Software Engineer Intern â€“ Data Platform  
**Honeywell Aerospace** | *Jan 2023 â€“ Jun 2023*
- Migrated **25+ years of unstructured and file-based data** into PostgreSQL, enabling analytics-ready datasets.
- Built Spring Boot microservices and REST APIs that reduced manual data lookup by **8â€“10 hours per week**.
- Designed relational schemas and wrote optimized SQL for reporting and analytics use cases.
- Applied **Python (NLTK, Pandas, NumPy)** for text mining and entity extraction from aerospace documents.
- Ensured pipeline reliability through data validation, testing, and monitoring.

---

## ğŸ“Œ Featured Projects

### ğŸ“Š YouTube Data ELT Pipeline
ğŸ”— https://github.com/vmadd24/YT_ELT  
End-to-end ELT pipeline using **Airflow, Docker, PostgreSQL**, YouTube API, with **SODA-based data quality checks** and GitHub Actions CI/CD.

### ğŸ“ˆ Impact of COVID-19 on Pharmaceutical Stocks
ğŸ”— https://github.com/vmadd24/Impact-Of-COVID19-On-Pharma-Sector  
Exploratory and statistical analysis on NIFTY Pharma Index data using hypothesis testing and visualization, identifying a **40% post-COVID price increase**.

### ğŸ— Construction Company Management System
ğŸ”— https://github.com/vmadd24/Construction-Company-Management-System  
Java-based system with normalized relational design for project tracking, employee management, and resource allocation.

---

## ğŸ“ Education
**M.S. in Computer Science** â€“ University of Illinois at Springfield | GPA: **4.0/4.0**  
**B.Tech in Computer Science & Engineering** â€“ Amrita Vishwa Vidyapeetham | GPA: **9.2/10**

---

## ğŸ† Highlights
- Graduated **First Class with Distinction** (Bachelorâ€™s)
- Recipient of **Amrita Vidyanidhi Scholarship** (75% tuition waiver)

---

â­ï¸ Open to **Backend Engineer, Data Engineer, and Platform Engineer** roles. Feel free to explore my repositories or connect with me!
